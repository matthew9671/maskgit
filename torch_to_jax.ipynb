{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4358aa57-c0bf-4783-aabc-dc108232511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90026bba-5305-4e2d-9bf6-b9db696920c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From VectorQuantizer2 in modules/vqvae/quantize.py\n",
    "class VectorQuantizer(nn.Module):\n",
    "    n_e: int\n",
    "    e_dim: int\n",
    "    beta: float\n",
    "    remap: str = None\n",
    "    unknown_index: str = \"random\"\n",
    "    sane_index_shape: bool = False\n",
    "    legacy: bool = True\n",
    "\n",
    "    def setup(self):\n",
    "        self.embedding = self.param('embedding', nn.initializers.uniform(scale=1.0 / self.n_e), (self.n_e, self.e_dim))\n",
    "        if self.remap is not None:\n",
    "            self.used = self.param('used', lambda rng, shape: jnp.array(np.load(self.remap)), (self.n_e,))\n",
    "            self.re_embed = self.used.shape[0]\n",
    "            if self.unknown_index == \"extra\":\n",
    "                self.unknown_index = self.re_embed\n",
    "                self.re_embed += 1\n",
    "            print(f\"Remapping {self.n_e} indices to {self.re_embed} indices. \"\n",
    "                  f\"Using {self.unknown_index} for unknown indices.\")\n",
    "        else:\n",
    "            self.re_embed = self.n_e\n",
    "\n",
    "    def remap_to_used(self, inds):\n",
    "        ishape = inds.shape\n",
    "        assert len(ishape) > 1\n",
    "        inds = inds.reshape(ishape[0], -1)\n",
    "        used = self.used\n",
    "        match = (inds[:, :, None] == used[None, None, ...]).astype(jnp.int32)\n",
    "        new = jnp.argmax(match, axis=-1)\n",
    "        unknown = jnp.sum(match, axis=-1) < 1\n",
    "        if self.unknown_index == \"random\":\n",
    "            new = jnp.where(unknown, jax.random.randint(jax.random.PRNGKey(0), new.shape, 0, self.re_embed), new)\n",
    "        else:\n",
    "            new = jnp.where(unknown, self.unknown_index, new)\n",
    "        return new.reshape(ishape)\n",
    "\n",
    "    def unmap_to_all(self, inds):\n",
    "        ishape = inds.shape\n",
    "        assert len(ishape) > 1\n",
    "        inds = inds.reshape(ishape[0], -1)\n",
    "        used = self.used\n",
    "        if self.re_embed > used.shape[0]:  # extra token\n",
    "            inds = jnp.where(inds >= used.shape[0], 0, inds)  # simply set to zero\n",
    "        back = used[inds]\n",
    "        return back.reshape(ishape)\n",
    "\n",
    "    def __call__(self, z, temp=None, rescale_logits=False, return_logits=False):\n",
    "        assert temp is None or temp == 1.0, \"Only for interface compatible with Gumbel\"\n",
    "        assert rescale_logits == False, \"Only for interface compatible with Gumbel\"\n",
    "        assert return_logits == False, \"Only for interface compatible with Gumbel\"\n",
    "        # z = jnp.transpose(z, (0, 2, 3, 1))\n",
    "        z_flattened = jnp.reshape(z, [-1, self.e_dim])\n",
    "\n",
    "        d = (jnp.sum(z_flattened ** 2, axis=1, keepdims=True) +\n",
    "             jnp.sum(self.embedding ** 2, axis=1) -\n",
    "             2 * jnp.dot(z_flattened, self.embedding.T))\n",
    "\n",
    "        min_encoding_indices = jnp.argmin(d, axis=1)\n",
    "        z_q = self.embedding[min_encoding_indices]\n",
    "        z_q = jnp.reshape(z_q, z.shape)\n",
    "\n",
    "        if not self.legacy:\n",
    "            loss = self.beta * jnp.mean((jax.lax.stop_gradient(z_q) - z) ** 2) + \\\n",
    "                   jnp.mean((z_q - jax.lax.stop_gradient(z)) ** 2)\n",
    "        else:\n",
    "            loss = jnp.mean((jax.lax.stop_gradient(z_q) - z) ** 2) + \\\n",
    "                   self.beta * jnp.mean((z_q - jax.lax.stop_gradient(z)) ** 2)\n",
    "\n",
    "        z_q = z + jax.lax.stop_gradient(z_q - z)\n",
    "\n",
    "        # z_q = jnp.transpose(z_q, (0, 3, 1, 2))\n",
    "\n",
    "        if self.remap is not None:\n",
    "            min_encoding_indices = min_encoding_indices.reshape(z.shape[0], -1)\n",
    "            min_encoding_indices = self.remap_to_used(min_encoding_indices)\n",
    "            min_encoding_indices = min_encoding_indices.reshape(-1)\n",
    "\n",
    "        if self.sane_index_shape:\n",
    "            min_encoding_indices = min_encoding_indices.reshape(z_q.shape[0], z_q.shape[2], z_q.shape[3])\n",
    "\n",
    "        return z_q, loss, (None, None, min_encoding_indices)\n",
    "\n",
    "    def get_codebook_entry(self, indices, shape):\n",
    "        if self.remap is not None:\n",
    "            indices = indices.reshape(shape[0], -1)\n",
    "            indices = self.unmap_to_all(indices)\n",
    "            indices = indices.reshape(-1)\n",
    "\n",
    "        z_q = self.embedding[indices]\n",
    "\n",
    "        if shape is not None:\n",
    "            z_q = z_q.reshape(shape)\n",
    "            # z_q = jnp.transpose(z_q, (0, 3, 1, 2))\n",
    "\n",
    "        return z_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb5a3fd-3065-4583-b967-2ed5f3637387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    \"\"\"\n",
    "    This matches the implementation in Denoising Diffusion Probabilistic Models:\n",
    "    From Fairseq.\n",
    "    Build sinusoidal embeddings.\n",
    "    This matches the implementation in tensor2tensor, but differs slightly\n",
    "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = jnp.log(10000) / (half_dim - 1)\n",
    "    emb = jnp.exp(jnp.arange(half_dim) * -emb)\n",
    "    emb = timesteps[:, None] * emb[None, :]\n",
    "    emb = jnp.concatenate([jnp.sin(emb), jnp.cos(emb)], axis=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = jnp.pad(emb, ((0, 0), (0, 1)))\n",
    "    return emb\n",
    "\n",
    "def nonlinearity(x):\n",
    "    # swish\n",
    "    return x * nn.sigmoid(x)\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    # in_channels: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        return nn.GroupNorm(num_groups=32, epsilon=1e-6, use_scale=True, use_bias=True)(x)\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    in_channels: int\n",
    "    with_conv: bool\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = jax.image.resize(x, (x.shape[0], x.shape[1] * 2, x.shape[2] * 2, x.shape[3]), method='nearest')\n",
    "        if self.with_conv:\n",
    "            x = nn.Conv(self.in_channels, kernel_size=(3, 3), strides=(1, 1), padding='SAME')(x)\n",
    "        return x\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    in_channels: int\n",
    "    with_conv: bool\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        if self.with_conv:\n",
    "            x = nn.Conv(self.in_channels, kernel_size=(3, 3), strides=(2, 2), padding='SAME')(x)\n",
    "        else:\n",
    "            x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    in_channels: int\n",
    "    out_channels: int = None\n",
    "    conv_shortcut: bool = False\n",
    "    dropout: float = 0.0\n",
    "    temb_channels: int = 512\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, temb, deterministic):\n",
    "        out_channels = self.in_channels if self.out_channels is None else self.out_channels\n",
    "\n",
    "        h = Normalize()(x)\n",
    "        h = nonlinearity(h)\n",
    "        h = nn.Conv(out_channels, kernel_size=(3, 3), strides=(1, 1), padding='SAME')(h)\n",
    "\n",
    "        if self.temb_channels > 0 and temb is not None:\n",
    "            h = h + nn.Dense(out_channels)(nonlinearity(temb))[:, None, None, :]\n",
    "\n",
    "        h = Normalize()(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = nn.Dropout(rate=self.dropout, deterministic=deterministic)(h)\n",
    "        h = nn.Conv(out_channels, kernel_size=(3, 3), strides=(1, 1), padding='SAME')(h)\n",
    "\n",
    "        if self.in_channels != out_channels:\n",
    "            if self.conv_shortcut:\n",
    "                x = nn.Conv(out_channels, kernel_size=(3, 3), strides=(1, 1), padding='SAME')(x)\n",
    "            else:\n",
    "                x = nn.Conv(out_channels, kernel_size=(1, 1), strides=(1, 1), padding='SAME')(x)\n",
    "\n",
    "        return x + h\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    in_channels: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # Normalize along the last dimension (channels)\n",
    "        h_ = Normalize()(x)\n",
    "        \n",
    "        # Apply 1x1 convolution to the last dimension (channels)\n",
    "        q = nn.Conv(self.in_channels, kernel_size=(1, 1))(h_)\n",
    "        k = nn.Conv(self.in_channels, kernel_size=(1, 1))(h_)\n",
    "        v = nn.Conv(self.in_channels, kernel_size=(1, 1))(h_)\n",
    "\n",
    "        # Get the shape of the input tensor\n",
    "        b, h, w, c = q.shape\n",
    "        \n",
    "        # Reshape the query, key, and value tensors\n",
    "        q = jnp.reshape(q, (b, h * w, c))\n",
    "        k = jnp.reshape(k, (b, h * w, c))\n",
    "        v = jnp.reshape(v, (b, h * w, c))\n",
    "        \n",
    "        # Transpose the key tensor\n",
    "        k = jnp.transpose(k, (0, 2, 1))  # (batch, channels, height * width)\n",
    "        \n",
    "        # Compute the attention weights\n",
    "        w_ = jnp.matmul(q, k) * (int(c) ** (-0.5))\n",
    "        # Normalize over the key dimension\n",
    "        w_ = nn.softmax(w_, axis=-1)\n",
    "        \n",
    "        # Apply the attention weights to the value tensor\n",
    "        h_ = jnp.matmul(w_, v)  # (batch, height * width. channels)\n",
    "        \n",
    "        # Reshape the result back to (batch, height, width, channels)\n",
    "        h_ = jnp.reshape(h_, (b, h, w, c))\n",
    "        \n",
    "        # Apply a final 1x1 convolution\n",
    "        h_ = nn.Conv(self.in_channels, kernel_size=(1, 1))(h_)\n",
    "\n",
    "        # Return the residual connection\n",
    "        return x + h_\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ch: int\n",
    "    out_ch: int\n",
    "    ch_mult: tuple = (1, 2, 4, 8)\n",
    "    num_res_blocks: int = 2\n",
    "    attn_resolutions: tuple = (16,)\n",
    "    dropout: float = 0.0\n",
    "    resamp_with_conv: bool = True\n",
    "    in_channels: int = 3 # not actually used \n",
    "    resolution: int = 256\n",
    "    z_channels: int = 256\n",
    "    double_z: bool = True\n",
    "\n",
    "    # def setup(self):\n",
    "    #     self.conv1 = nn.Conv(self.ch, kernel_size=(3, 3), strides=(1, 1), padding='SAME')\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, deterministic):\n",
    "        temb = None\n",
    "        hs = [nn.Conv(self.ch, kernel_size=(3, 3), strides=(1, 1), padding='SAME')(x)]\n",
    "        # hs = [self.conv1(x)]\n",
    "        curr_res = self.resolution\n",
    "\n",
    "        for i_level in range(len(self.ch_mult)):\n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                h = ResnetBlock(in_channels=hs[-1].shape[-1], out_channels=self.ch * self.ch_mult[i_level], \n",
    "                                temb_channels=0, dropout=self.dropout)(hs[-1], temb, deterministic)\n",
    "                if curr_res in self.attn_resolutions:\n",
    "                    h = AttnBlock(in_channels=h.shape[-1])(h)\n",
    "                hs.append(h)\n",
    "            if i_level != len(self.ch_mult) - 1:\n",
    "                hs.append(Downsample(in_channels=h.shape[-1], with_conv=self.resamp_with_conv)(hs[-1]))\n",
    "                curr_res //= 2\n",
    "\n",
    "        h = ResnetBlock(in_channels=hs[-1].shape[-1], out_channels=hs[-1].shape[-1], \n",
    "                        temb_channels=0, dropout=self.dropout)(hs[-1], temb, deterministic)\n",
    "        h = AttnBlock(in_channels=h.shape[-1])(h)\n",
    "        h = ResnetBlock(in_channels=h.shape[-1], out_channels=hs[-1].shape[-1], \n",
    "                        temb_channels=0, dropout=self.dropout)(h, temb, deterministic)\n",
    "\n",
    "        h = Normalize()(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = nn.Conv(2 * self.z_channels if self.double_z else self.z_channels, \n",
    "                    kernel_size=(3, 3), strides=(1, 1), padding='SAME')(h)\n",
    "        return h\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ch: int\n",
    "    out_ch: int\n",
    "    ch_mult: tuple = (1, 2, 4, 8)\n",
    "    num_res_blocks: int = 2\n",
    "    attn_resolutions: tuple = (16,)\n",
    "    dropout: float = 0.0\n",
    "    resamp_with_conv: bool = True\n",
    "    in_channels: int = 3 # not actually used\n",
    "    resolution: int = 256\n",
    "    z_channels: int = 256\n",
    "    give_pre_end: bool = False\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, z, deterministic):\n",
    "        temb = None\n",
    "        block_in = self.ch * self.ch_mult[-1]\n",
    "        curr_res = self.resolution // 2 ** (len(self.ch_mult) - 1)\n",
    "        h = nn.Conv(block_in, kernel_size=(3, 3), strides=(1, 1), padding='SAME')(z)\n",
    "\n",
    "        h = ResnetBlock(in_channels=block_in, out_channels=block_in, \n",
    "                        temb_channels=0, dropout=self.dropout)(h, temb, deterministic)\n",
    "        h = AttnBlock(in_channels=block_in)(h)\n",
    "        h = ResnetBlock(in_channels=block_in, out_channels=block_in, \n",
    "                        temb_channels=0, dropout=self.dropout)(h, temb, deterministic)\n",
    "\n",
    "        for i_level in reversed(range(len(self.ch_mult))):\n",
    "            for i_block in range(self.num_res_blocks + 1):\n",
    "                h = ResnetBlock(in_channels=h.shape[-1], out_channels=self.ch * self.ch_mult[i_level], \n",
    "                                temb_channels=0, dropout=self.dropout)(h, temb, deterministic)\n",
    "                if curr_res in self.attn_resolutions:\n",
    "                    h = AttnBlock(in_channels=h.shape[-1])(h)\n",
    "            if i_level != 0:\n",
    "                h = Upsample(in_channels=h.shape[-1], with_conv=self.resamp_with_conv)(h)\n",
    "                curr_res *= 2\n",
    "\n",
    "        if self.give_pre_end:\n",
    "            return h\n",
    "\n",
    "        h = Normalize()(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = nn.Conv(self.out_ch, kernel_size=(3, 3), strides=(1, 1), padding='SAME')(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d1aa75f-afeb-441d-988a-3dc34456aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQModel(nn.Module):\n",
    "    ddconfig: dict\n",
    "    lossconfig: dict\n",
    "    n_embed: int\n",
    "    embed_dim: int\n",
    "    ckpt_path: str = None\n",
    "    ignore_keys: list = None\n",
    "    image_key: str = \"image\"\n",
    "    colorize_nlabels: int = None\n",
    "    monitor: str = None\n",
    "    remap: None = None\n",
    "    sane_index_shape: bool = False\n",
    "\n",
    "    def setup(self):\n",
    "        self.encoder = Encoder(**self.ddconfig)\n",
    "        self.decoder = Decoder(**self.ddconfig)\n",
    "        self.quantize = VectorQuantizer(n_e=self.n_embed, e_dim=self.embed_dim, \n",
    "                                        beta=0.25, remap=self.remap, sane_index_shape=self.sane_index_shape)\n",
    "        self.quant_conv = nn.Conv(self.embed_dim, (1, 1))\n",
    "        self.post_quant_conv = nn.Conv(self.ddconfig[\"z_channels\"], (1, 1))\n",
    "\n",
    "        if self.colorize_nlabels is not None:\n",
    "            self.colorize = self.param('colorize', nn.initializers.normal(), (3, self.colorize_nlabels, 1, 1))\n",
    "\n",
    "    def encode(self, x, train):\n",
    "        h = self.encoder(x, deterministic=not train)\n",
    "        h = self.quant_conv(h)\n",
    "        quant, emb_loss, info = self.quantize(h)\n",
    "        return quant, emb_loss, info\n",
    "\n",
    "    def decode(self, quant, train):\n",
    "        quant = self.post_quant_conv(quant)\n",
    "        dec = self.decoder(quant, deterministic=not train)\n",
    "        return dec\n",
    "\n",
    "    def decode_code(self, code_b, train):\n",
    "        # TODO: is the shape here correct?\n",
    "        quant_b = self.quantize.get_codebook_entry(code_b.reshape(-1), (-1, code_b.shape[1], code_b.shape[2], self.embed_dim))\n",
    "        dec = self.decode(quant_b, train)\n",
    "        return dec\n",
    "\n",
    "    def __call__(self, input, train):\n",
    "        quant, diff, _ = self.encode(input, train)\n",
    "        dec = self.decode(quant, train)\n",
    "        return dec, diff\n",
    "\n",
    "    def get_input(self, batch, k):\n",
    "        x = batch[k]\n",
    "        if len(x.shape) == 3:\n",
    "            x = jnp.expand_dims(x, axis=-1)\n",
    "        # We're working with (N, H, W, C) already\n",
    "        # x = jnp.transpose(x, (0, 3, 1, 2))\n",
    "        return x.astype(jnp.float32)\n",
    "\n",
    "    def training_step(self, state, batch, optimizer_idx):\n",
    "        x = self.get_input(batch, self.image_key)\n",
    "        xrec, qloss = self(x, train=True)\n",
    "\n",
    "        def loss_fn(params):\n",
    "            if optimizer_idx == 0:\n",
    "                aeloss, log_dict_ae = self.loss(qloss, x, xrec, optimizer_idx, state.step, \n",
    "                                                last_layer=self.get_last_layer(), split=\"train\")\n",
    "                return aeloss\n",
    "\n",
    "            if optimizer_idx == 1:\n",
    "                discloss, log_dict_disc = self.loss(qloss, x, xrec, optimizer_idx, state.step, \n",
    "                                                    last_layer=self.get_last_layer(), split=\"train\")\n",
    "                return discloss\n",
    "\n",
    "        grad_fn = jax.value_and_grad(loss_fn)\n",
    "        loss, grads = grad_fn(state.params)\n",
    "        state = state.apply_gradients(grads=grads)\n",
    "        return state, loss\n",
    "\n",
    "    def validation_step(self, state, batch):\n",
    "        x = self.get_input(batch, self.image_key)\n",
    "        xrec, qloss = self(x)\n",
    "        aeloss, log_dict_ae = self.loss(qloss, x, xrec, 0, state.step, \n",
    "                                        last_layer=self.get_last_layer(), split=\"val\")\n",
    "        discloss, log_dict_disc = self.loss(qloss, x, xrec, 1, state.step, \n",
    "                                            last_layer=self.get_last_layer(), split=\"val\")\n",
    "        rec_loss = log_dict_ae[\"val/rec_loss\"]\n",
    "        logs = {\"val/rec_loss\": rec_loss, \"val/aeloss\": aeloss}\n",
    "        logs.update(log_dict_ae)\n",
    "        logs.update(log_dict_disc)\n",
    "        return logs\n",
    "\n",
    "    def configure_optimizers(self, lr):\n",
    "        optimizer = optax.adam(learning_rate=lr, b1=0.5, b2=0.9)\n",
    "        return optimizer\n",
    "\n",
    "    def get_last_layer(self):\n",
    "        return self.decoder.layers[-1].kernel\n",
    "\n",
    "    def log_images(self, batch):\n",
    "        x = self.get_input(batch, self.image_key)\n",
    "        xrec, _ = self(x)\n",
    "        if x.shape[-1] > 3:\n",
    "            x = self.to_rgb(x)\n",
    "            xrec = self.to_rgb(xrec)\n",
    "        return {\"inputs\": x, \"reconstructions\": xrec}\n",
    "\n",
    "    def to_rgb(self, x):\n",
    "        assert self.image_key == \"segmentation\"\n",
    "        x = jax.lax.conv_general_dilated(x, self.colorize, window_strides=(1, 1), padding='SAME')\n",
    "        x = 2. * (x - jnp.min(x)) / (jnp.max(x) - jnp.min(x)) - 1.\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d64cef4-3946-4ae3-8ae1-d054a212683d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\"VQModel\" object has no attribute \"loss\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m batch \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: jnp\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m3\u001b[39m))}\n\u001b[1;32m     21\u001b[0m optimizer_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 22\u001b[0m state, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 71\u001b[0m, in \u001b[0;36mVQModel.training_step\u001b[0;34m(self, state, batch, optimizer_idx)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m discloss\n\u001b[1;32m     70\u001b[0m grad_fn \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(loss_fn)\n\u001b[0;32m---> 71\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mapply_gradients(grads\u001b[38;5;241m=\u001b[39mgrads)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, loss\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 61\u001b[0m, in \u001b[0;36mVQModel.training_step.<locals>.loss_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(params):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m optimizer_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 61\u001b[0m         aeloss, log_dict_ae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m(qloss, x, xrec, optimizer_idx, state\u001b[38;5;241m.\u001b[39mstep, \n\u001b[1;32m     62\u001b[0m                                         last_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_last_layer(), split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m aeloss\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m optimizer_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jax_tpu_py39/lib/python3.9/site-packages/flax/linen/module.py:1326\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1322\u001b[0m   msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m If \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is defined in \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m.setup()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m, remember these fields \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare only accessible from inside \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1325\u001b[0m   )\n\u001b[0;32m-> 1326\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: \"VQModel\" object has no attribute \"loss\"."
     ]
    }
   ],
   "source": [
    "# Example of how to initialize and use the model\n",
    "ddconfig = {\n",
    "    \"ch\": 128,\n",
    "    \"out_ch\": 3,\n",
    "    \"z_channels\": 256\n",
    "}\n",
    "lossconfig = {}\n",
    "n_embed = 512\n",
    "embed_dim = 64\n",
    "\n",
    "model = VQModel(ddconfig=ddconfig, lossconfig=lossconfig, n_embed=n_embed, embed_dim=embed_dim)\n",
    "\n",
    "# Optimizer and state initialization\n",
    "lr = 1e-4\n",
    "optimizer = model.configure_optimizers(lr)\n",
    "state = train_state.TrainState.create(apply_fn=model.apply, \n",
    "        params=model.init(jax.random.PRNGKey(0), jnp.ones((1, 256, 256, 3)), train=True), tx=optimizer)\n",
    "\n",
    "# Example training step\n",
    "batch = {\"image\": jnp.ones((1, 256, 256, 3))}\n",
    "optimizer_idx = 0\n",
    "state, loss = model.apply(state.params, state, batch, optimizer_idx, method=model.training_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1152a3e9-68f2-4931-8592-8c9e6707ba02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.apply(state.params, batch[\"image\"], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c1963-646e-4f21-8a54-c91b725af099",
   "metadata": {},
   "source": [
    "# Torch parameters to JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eb94da35-93e3-4254-a4ee-3a9c9a31fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class SimpleCNN(tnn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.out_ch = 4\n",
    "        self.size = 16\n",
    "        self.conv1 = tnn.Conv2d(in_channels=3, out_channels=self.out_ch, kernel_size=3, stride=1, padding=1)\n",
    "        # self.conv2 = tnn.Conv2d(in_channels=16, out_channels=self.out_ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = tnn.Linear(self.out_ch * self.size ** 2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.relu(self.conv2(x))\n",
    "        # x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, self.out_ch * self.size ** 2)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Initialize PyTorch model\n",
    "pytorch_model = SimpleCNN()\n",
    "pytorch_model.eval()\n",
    "\n",
    "# Input tensor\n",
    "input_tensor = torch.randn(1, 3, 16, 16)\n",
    "# input_tensor = torch.ones((1, 3, 16, 16))\n",
    "\n",
    "# Forward pass in PyTorch\n",
    "pytorch_output = pytorch_model(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d453c512-8703-4985-8093-6310b3352edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_0 {'bias': (4,), 'kernel': (3, 3, 3, 4)}\n",
      "Dense_0 {'bias': (10,), 'kernel': (784, 10)}\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from flax.core import freeze, unfreeze\n",
    "\n",
    "class SimpleCNNJax(jnn.Module):\n",
    "    @jnn.compact\n",
    "    def __call__(self, x):\n",
    "        x = jnn.Conv(features=4, kernel_size=(3, 3), strides=(1, 1), padding='VALID')(x)\n",
    "        # x = jnn.relu(x)\n",
    "        # x = jnn.Conv(features=32, kernel_size=(3, 3), strides=(1, 1), padding='SAME')(x)\n",
    "        # x = jnn.relu(x)\n",
    "        # # x = jnn.max_pool(x, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n",
    "        x = x.transpose((0, 3, 1, 2))\n",
    "        x = x.reshape((x.shape[0], -1))  # Flatten\n",
    "        x = jnn.Dense(features=10)(x)\n",
    "        return x\n",
    "\n",
    "# Initialize JAX model\n",
    "jax_model = SimpleCNNJax()\n",
    "variables = jax_model.init(jax.random.PRNGKey(0), jnp.ones((1, 16, 16, 3)))  # Note input shape difference\n",
    "\n",
    "# JAX model shapes\n",
    "for param_name, param_value in variables['params'].items():\n",
    "    print(param_name, jax.tree_util.tree_map(jnp.shape, param_value))\n",
    "\n",
    "# Forward pass in JAX\n",
    "jax_input = input_tensor.detach().numpy().transpose(0, 2, 3, 1)#jnp.ones((1, 16, 16, 3))  # Note input shape difference\n",
    "jax_output = jax_model.apply(variables, jax_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e42025bd-b8bd-4c7c-814e-2cb689505e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight (4, 3, 3, 3)\n",
      "conv1.bias (4,)\n",
      "fc1.weight (10, 1024)\n",
      "fc1.bias (10,)\n"
     ]
    }
   ],
   "source": [
    "foo = pytorch_model.named_parameters()\n",
    "for n, p in foo:\n",
    "    print(n, p.detach().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c655e753-3ed3-4fbc-91a6-3da3d09b7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PyTorch parameters\n",
    "pytorch_params = {name: param.detach().numpy() for name, param in pytorch_model.named_parameters()}\n",
    "\n",
    "# Transpose convolution kernels to JAX format\n",
    "jax_params = {}\n",
    "jax_params['params'] = {\n",
    "    'Conv_0': {\n",
    "        'kernel': jnp.transpose(pytorch_params['conv1.weight'], (2, 3, 1, 0)),  # (H, W, in_channels, out_channels)\n",
    "        'bias': pytorch_params['conv1.bias']\n",
    "    },\n",
    "    # 'Conv_1': {\n",
    "    #     'kernel': jnp.transpose(pytorch_params['conv2.weight'], (2, 3, 1, 0)),  # (H, W, in_channels, out_channels)\n",
    "    #     'bias': pytorch_params['conv2.bias']\n",
    "    # },\n",
    "    'Dense_0': {\n",
    "        'kernel': jnp.transpose(pytorch_params['fc1.weight'], (1, 0)),  # (in_features, out_features)\n",
    "        'bias': pytorch_params['fc1.bias']\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "759e8dec-920c-4572-a057-93ace9f304a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ScopeParamShapeError",
     "evalue": "Initializer expected to generate shape (1024, 10) but got shape (784, 10) instead for parameter \"kernel\" in \"/Dense_0\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScopeParamShapeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply JAX model with converted parameters\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m jax_output_with_converted_weights \u001b[38;5;241m=\u001b[39m \u001b[43mjax_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjax_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjax_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Convert JAX output to numpy for comparison\u001b[39;00m\n\u001b[1;32m      5\u001b[0m jax_output_with_converted_weights_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(jax_output_with_converted_weights)\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[128], line 16\u001b[0m, in \u001b[0;36mSimpleCNNJax.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Flatten\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mjnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax_tpu_py39/lib/python3.9/site-packages/flax/linen/linear.py:256\u001b[0m, in \u001b[0;36mDense.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;129m@compact\u001b[39m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Array) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m    248\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Applies a linear transformation to the inputs along the last dimension.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    The transformed input.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m   kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m    263\u001b[0m     bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam(\n\u001b[1;32m    264\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_init, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures,), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_dtype\n\u001b[1;32m    265\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax_tpu_py39/lib/python3.9/site-packages/flax/core/scope.py:982\u001b[0m, in \u001b[0;36mScope.param\u001b[0;34m(self, name, init_fn, unbox, *init_args, **init_kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m val, abs_val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(value_flat, abs_value_flat):\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# NOTE: We could check dtype consistency here as well but it's\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# usefuleness is less obvious. We might intentionally change the dtype\u001b[39;00m\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;66;03m# for inference to a half float type for example.\u001b[39;00m\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mshape(val) \u001b[38;5;241m!=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mshape(abs_val):\n\u001b[0;32m--> 982\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mScopeParamShapeError(\n\u001b[1;32m    983\u001b[0m         name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_text, jnp\u001b[38;5;241m.\u001b[39mshape(abs_val), jnp\u001b[38;5;241m.\u001b[39mshape(val)\n\u001b[1;32m    984\u001b[0m       )\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mutable_collection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mScopeParamShapeError\u001b[0m: Initializer expected to generate shape (1024, 10) but got shape (784, 10) instead for parameter \"kernel\" in \"/Dense_0\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)"
     ]
    }
   ],
   "source": [
    "# Apply JAX model with converted parameters\n",
    "jax_output_with_converted_weights = jax_model.apply(freeze(jax_params), jax_input)\n",
    "\n",
    "# Convert JAX output to numpy for comparison\n",
    "jax_output_with_converted_weights_np = np.array(jax_output_with_converted_weights)\n",
    "\n",
    "# pytorch_output_transposed = pytorch_output.detach().numpy().transpose((0, 2, 3, 1))\n",
    "pytorch_output_transposed = pytorch_output.detach().numpy()\n",
    "\n",
    "# Check if PyTorch and JAX outputs are close\n",
    "print(\"PyTorch Output:\", pytorch_output_transposed.shape)\n",
    "print(\"JAX Output with Converted Weights:\", jax_output_with_converted_weights_np.shape)\n",
    "\n",
    "# Verify outputs are close\n",
    "assert np.allclose(pytorch_output_transposed, jax_output_with_converted_weights_np, atol=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "da41710d-2ec3-4740-8047-c5218b0082ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.51111966 -0.04593015 -0.1496524   0.2616843   0.30416355 -0.33370522\n",
      "   0.10532388 -0.18177658  0.39548695 -0.08444177]]\n",
      "[[ 0.5117992  -0.04623537 -0.15025586  0.26086736  0.30316165 -0.3335306\n",
      "   0.10542459 -0.18202648  0.3946072  -0.08543608]]\n"
     ]
    }
   ],
   "source": [
    "print(jax_output_with_converted_weights_np)\n",
    "print(pytorch_output_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b67d5561-cb6d-4201-9256-aa17c64b7a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f1d57dcd3d0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(input_tensor.detach().numpy()[0,0,...])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5f804852-d416-4b25-b797-ecb1b67d73bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f1d52700a90>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(input_tensor.detach().numpy()[0,0] - jax_input[0,...,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "20b56f48-84b4-4411-985b-f760ede4dbd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape () for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpytorch_output_transposed\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mjax_output_with_converted_weights_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n",
      "File \u001b[0;32m~/miniconda3/envs/jax_tpu_py39/lib/python3.9/site-packages/matplotlib/pyplot.py:3562\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   3542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   3543\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3560\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3561\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3562\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3571\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3573\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3581\u001b[0m     sci(__ret)\n\u001b[1;32m   3582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/miniconda3/envs/jax_tpu_py39/lib/python3.9/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/miniconda3/envs/jax_tpu_py39/lib/python3.9/site-packages/matplotlib/axes/_axes.py:5895\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5895\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5896\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax_tpu_py39/lib/python3.9/site-packages/matplotlib/image.py:729\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    728\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax_tpu_py39/lib/python3.9/site-packages/matplotlib/image.py:697\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    695\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape () for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow((pytorch_output_transposed-jax_output_with_converted_weights_np)[0, ..., 2])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32205d3b-004c-4395-973e-0ed3620705ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858efcd-81a2-46ef-919b-7dd33f7dfc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VQModel(nn.Module):\n",
    "    \n",
    "#     encoder: nn.Module = None\n",
    "#     decoder: nn.Module = None\n",
    "#     quantize: nn.Module = None\n",
    "#     quant_conv: nn.Module = None\n",
    "#     post_quant_conv: nn.Module = None\n",
    "#     colorize: None = None\n",
    "    \n",
    "#     # ddconfig: dict\n",
    "#     # lossconfig: dict\n",
    "#     # n_embed: int\n",
    "#     embed_dim: int\n",
    "#     ckpt_path: str = None\n",
    "#     ignore_keys: list = None\n",
    "#     image_key: str = \"image\"\n",
    "#     # colorize_nlabels: int = None\n",
    "#     monitor: str = None\n",
    "#     remap: None = None\n",
    "#     # sane_index_shape: bool = False\n",
    "\n",
    "#     # def setup(self):\n",
    "#     #     self.encoder = Encoder(**self.ddconfig)\n",
    "#     #     self.decoder = Decoder(**self.ddconfig)\n",
    "#     #     self.quantize = VectorQuantizer(n_e=self.n_embed, e_dim=self.embed_dim, \n",
    "#     #                                     beta=0.25, remap=self.remap, sane_index_shape=self.sane_index_shape)\n",
    "#     #     self.quant_conv = nn.Conv(self.embed_dim, (1, 1))\n",
    "#     #     self.post_quant_conv = nn.Conv(self.ddconfig[\"z_channels\"], (1, 1))\n",
    "\n",
    "#     #     if self.colorize_nlabels is not None:\n",
    "#     #         self.colorize = self.param('colorize', nn.initializers.normal(), (3, self.colorize_nlabels, 1, 1))\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_params(cls, ddconfig, lossconfig, n_embed, embed_dim, \n",
    "#         ckpt_path=None, ignore_keys=None, image_key=\"image\", colorize_nlabels=None,\n",
    "#         monitor=None, remap=None, sane_index_shape=False):\n",
    "#         encoder = Encoder(**ddconfig)\n",
    "#         decoder = Decoder(**ddconfig)\n",
    "#         quantize = VectorQuantizer(n_e=n_embed, e_dim=embed_dim, \n",
    "#                                    beta=0.25, remap=remap, sane_index_shape=sane_index_shape)\n",
    "#         quant_conv = nn.Conv(embed_dim, (1, 1))\n",
    "#         post_quant_conv = nn.Conv(ddconfig[\"z_channels\"], (1, 1))\n",
    "\n",
    "#         # What is this??\n",
    "#         if colorize_nlabels is not None:\n",
    "#             colorize = self.param('colorize', nn.initializers.normal(), (3, self.colorize_nlabels, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20e8a3ef-e686-4e20-a8fa-05880a0ea4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.4476189613342285\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax.training import train_state\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    latent_dim: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.dense1 = nn.Dense(features=128)\n",
    "        self.dense2 = nn.Dense(features=64)\n",
    "        self.mean_dense = nn.Dense(features=self.latent_dim)\n",
    "        self.logvar_dense = nn.Dense(features=self.latent_dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = nn.relu(self.dense1(x))\n",
    "        x = nn.relu(self.dense2(x))\n",
    "        mean = self.mean_dense(x)\n",
    "        logvar = self.logvar_dense(x)\n",
    "        return mean, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    output_dim: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.dense1 = nn.Dense(features=64)\n",
    "        self.dense2 = nn.Dense(features=128)\n",
    "        self.output_dense = nn.Dense(features=self.output_dim)\n",
    "\n",
    "    def __call__(self, z):\n",
    "        z = nn.relu(self.dense1(z))\n",
    "        z = nn.relu(self.dense2(z))\n",
    "        z = nn.sigmoid(self.output_dense(z))\n",
    "        return z\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    latent_dim: int\n",
    "    output_dim: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.encoder = Encoder(latent_dim=self.latent_dim)\n",
    "        self.decoder = Decoder(output_dim=self.output_dim)\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = jnp.exp(0.5 * logvar)\n",
    "        eps = jax.random.normal(self.make_rng('dropout'), mean.shape)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def __call__(self, x, deterministic=True):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        reconstructed_x = self.decoder(z)\n",
    "        return reconstructed_x, mean, logvar\n",
    "\n",
    "# Example usage\n",
    "vae = VAE(latent_dim=10, output_dim=784)\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "dummy_input = jnp.ones((1, 784))  # Example input\n",
    "params = vae.init(rng, dummy_input)\n",
    "\n",
    "# Define forward pass function\n",
    "def forward_pass(params, x, rng):\n",
    "    return vae.apply(params, x, rngs={'dropout': rng})\n",
    "\n",
    "# Example forward pass\n",
    "rng = jax.random.PRNGKey(1)\n",
    "x = jax.random.normal(rng, (1, 784))\n",
    "reconstructed_x, mean, logvar = forward_pass(params, x, rng)\n",
    "\n",
    "# Training step function\n",
    "@jax.jit\n",
    "def train_step(state, batch, rng):\n",
    "    def loss_fn(params):\n",
    "        reconstructed_x, mean, logvar = forward_pass(params, batch, rng)\n",
    "        reconstruction_loss = jnp.mean(jnp.square(reconstructed_x - batch))\n",
    "        kl_divergence = -0.5 * jnp.mean(1 + logvar - jnp.square(mean) - jnp.exp(logvar))\n",
    "        loss = reconstruction_loss + kl_divergence\n",
    "        return loss\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "\n",
    "# Initialize optimizer and training state\n",
    "optimizer = optax.adam(learning_rate=1e-3)\n",
    "state = train_state.TrainState.create(apply_fn=vae.apply, params=params, tx=optimizer)\n",
    "\n",
    "# Example training step\n",
    "rng, step_rng = jax.random.split(rng)\n",
    "state, loss = train_step(state, x, step_rng)\n",
    "\n",
    "print(f\"Training loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5aac871-bffe-4ad1-a75d-28125eef0fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[0.59782356, 0.48028037, 0.5268784 , 0.5412499 , 0.47357202,\n",
       "         0.5295619 , 0.55362946, 0.40527472, 0.41515607, 0.47278085,\n",
       "         0.3736489 , 0.6215862 , 0.4283234 , 0.5297417 , 0.47881293,\n",
       "         0.5251219 , 0.5943308 , 0.56700146, 0.48229563, 0.5048226 ,\n",
       "         0.3958562 , 0.60273117, 0.59007645, 0.4164364 , 0.54597217,\n",
       "         0.53243494, 0.5871151 , 0.51926935, 0.4613332 , 0.50815547,\n",
       "         0.45364735, 0.4747558 , 0.505987  , 0.5269336 , 0.38053897,\n",
       "         0.55809027, 0.44448796, 0.47760388, 0.5172707 , 0.48258492,\n",
       "         0.39854977, 0.57031465, 0.45915866, 0.5885839 , 0.5549953 ,\n",
       "         0.4484396 , 0.41627893, 0.5520951 , 0.5824886 , 0.55574363,\n",
       "         0.5655874 , 0.60568774, 0.484931  , 0.54635173, 0.5347197 ,\n",
       "         0.5201308 , 0.50564045, 0.51796824, 0.5792515 , 0.5502594 ,\n",
       "         0.59239864, 0.45128104, 0.53559744, 0.47412473, 0.5295527 ,\n",
       "         0.46331114, 0.53153205, 0.46626937, 0.48959446, 0.5379729 ,\n",
       "         0.4250202 , 0.47033706, 0.44528496, 0.52474076, 0.42995775,\n",
       "         0.47183523, 0.49665818, 0.53258264, 0.5852597 , 0.55461866,\n",
       "         0.5951631 , 0.5476991 , 0.5235748 , 0.5117078 , 0.48831666,\n",
       "         0.38791445, 0.4947308 , 0.4290914 , 0.46749586, 0.42546642,\n",
       "         0.4597331 , 0.5282411 , 0.5169636 , 0.55490583, 0.4565537 ,\n",
       "         0.57070065, 0.58015513, 0.44072992, 0.44396177, 0.53144777,\n",
       "         0.44292435, 0.53856957, 0.5539565 , 0.4215931 , 0.507648  ,\n",
       "         0.57745343, 0.37751627, 0.54032815, 0.37829813, 0.5546306 ,\n",
       "         0.5231067 , 0.52409476, 0.43869   , 0.516181  , 0.5455535 ,\n",
       "         0.37391815, 0.4402671 , 0.44863963, 0.45839974, 0.54731226,\n",
       "         0.5376852 , 0.4618504 , 0.45604962, 0.47464424, 0.71234566,\n",
       "         0.4899607 , 0.48090667, 0.524105  , 0.59175307, 0.41598356,\n",
       "         0.51977605, 0.48085126, 0.48214036, 0.48620892, 0.39989528,\n",
       "         0.47117695, 0.48021224, 0.48533827, 0.4773453 , 0.5622322 ,\n",
       "         0.41939402, 0.49476334, 0.5211893 , 0.5578551 , 0.4380661 ,\n",
       "         0.52621406, 0.5329886 , 0.5048535 , 0.50178564, 0.5270206 ,\n",
       "         0.47451973, 0.43505734, 0.5046626 , 0.5459244 , 0.5470197 ,\n",
       "         0.48845434, 0.54756   , 0.5507845 , 0.45138153, 0.5058057 ,\n",
       "         0.5826401 , 0.5417129 , 0.5049236 , 0.40098384, 0.5201543 ,\n",
       "         0.4818125 , 0.6270194 , 0.53907436, 0.62454367, 0.4982315 ,\n",
       "         0.5774093 , 0.60415286, 0.49643573, 0.5659928 , 0.4669579 ,\n",
       "         0.55662197, 0.5643804 , 0.4285826 , 0.48653513, 0.485261  ,\n",
       "         0.46204564, 0.45391303, 0.4861816 , 0.6061903 , 0.56409746,\n",
       "         0.54096377, 0.48349828, 0.3962917 , 0.4993035 , 0.46921816,\n",
       "         0.50872654, 0.61344063, 0.48021883, 0.36001208, 0.56161153,\n",
       "         0.48162952, 0.44948378, 0.52637416, 0.5049854 , 0.41589713,\n",
       "         0.49804205, 0.5330482 , 0.49233127, 0.4513726 , 0.59796417,\n",
       "         0.55704665, 0.5259357 , 0.48111314, 0.36744365, 0.4492578 ,\n",
       "         0.5056892 , 0.5048241 , 0.5201272 , 0.6014734 , 0.5033623 ,\n",
       "         0.44540074, 0.5299907 , 0.6071762 , 0.52867216, 0.46978194,\n",
       "         0.47186658, 0.41519988, 0.4781695 , 0.59361106, 0.5340304 ,\n",
       "         0.50490296, 0.4584254 , 0.47369462, 0.5308742 , 0.4565056 ,\n",
       "         0.48547623, 0.59674853, 0.5212606 , 0.5015076 , 0.5072645 ,\n",
       "         0.47868302, 0.4253915 , 0.48044956, 0.4640237 , 0.59059614,\n",
       "         0.52121836, 0.5031649 , 0.6008597 , 0.42704362, 0.47119617,\n",
       "         0.5453722 , 0.46283844, 0.48945343, 0.5099894 , 0.40942886,\n",
       "         0.45028162, 0.45361203, 0.5613183 , 0.4041763 , 0.49939063,\n",
       "         0.63314575, 0.4711948 , 0.47820318, 0.451949  , 0.5427748 ,\n",
       "         0.4262356 , 0.4425754 , 0.5362935 , 0.50969   , 0.50896496,\n",
       "         0.5122675 , 0.6492443 , 0.5213038 , 0.4421406 , 0.5659144 ,\n",
       "         0.54433256, 0.39421976, 0.45502353, 0.5378962 , 0.58835876,\n",
       "         0.5623452 , 0.41843194, 0.53370786, 0.50074166, 0.5042827 ,\n",
       "         0.4731488 , 0.47923434, 0.51947737, 0.37868613, 0.43705916,\n",
       "         0.539683  , 0.5541545 , 0.4643615 , 0.5863913 , 0.4583483 ,\n",
       "         0.41794276, 0.478876  , 0.5049384 , 0.46146742, 0.54139006,\n",
       "         0.41174442, 0.4801237 , 0.4375288 , 0.5276811 , 0.5479263 ,\n",
       "         0.48213163, 0.5227895 , 0.39922225, 0.4338258 , 0.53611755,\n",
       "         0.5115464 , 0.5302944 , 0.50284135, 0.4490776 , 0.48938677,\n",
       "         0.46773762, 0.38251516, 0.49155948, 0.5223498 , 0.5048929 ,\n",
       "         0.49635857, 0.49876952, 0.5561676 , 0.4633168 , 0.43853828,\n",
       "         0.4824887 , 0.56686664, 0.5152705 , 0.47558138, 0.47987866,\n",
       "         0.48924473, 0.60287684, 0.4550587 , 0.516049  , 0.51887083,\n",
       "         0.5005121 , 0.4688654 , 0.4659146 , 0.50045645, 0.42761758,\n",
       "         0.5248753 , 0.5438127 , 0.48725528, 0.562661  , 0.56456393,\n",
       "         0.60998183, 0.48642814, 0.44002137, 0.48636004, 0.58592135,\n",
       "         0.5769428 , 0.58470887, 0.5174916 , 0.5282091 , 0.43291312,\n",
       "         0.49700186, 0.5009948 , 0.46223786, 0.47150594, 0.51705676,\n",
       "         0.46790624, 0.41527838, 0.5694577 , 0.58696586, 0.5169578 ,\n",
       "         0.59019345, 0.5671023 , 0.42479557, 0.44229195, 0.513083  ,\n",
       "         0.50211924, 0.42066905, 0.5875068 , 0.5219263 , 0.47905493,\n",
       "         0.44775692, 0.53548086, 0.47041345, 0.5204849 , 0.5314695 ,\n",
       "         0.5293162 , 0.5401103 , 0.44134158, 0.49851596, 0.48903915,\n",
       "         0.57850504, 0.5694844 , 0.44248378, 0.57973933, 0.5107718 ,\n",
       "         0.48277748, 0.32096025, 0.47127223, 0.48061544, 0.41147387,\n",
       "         0.47867635, 0.4362605 , 0.54900396, 0.56264126, 0.42888546,\n",
       "         0.5321829 , 0.6088496 , 0.524403  , 0.4416403 , 0.42872   ,\n",
       "         0.57205796, 0.31987077, 0.44024315, 0.50635725, 0.48067933,\n",
       "         0.54466945, 0.45696002, 0.5396387 , 0.4651056 , 0.39447016,\n",
       "         0.49051163, 0.51861894, 0.45687237, 0.43168366, 0.47275314,\n",
       "         0.505826  , 0.6121318 , 0.4341402 , 0.48727235, 0.5388092 ,\n",
       "         0.38299915, 0.4051901 , 0.5822187 , 0.49616557, 0.4178715 ,\n",
       "         0.52179724, 0.43421286, 0.50892884, 0.44742298, 0.54153347,\n",
       "         0.59182113, 0.48307315, 0.56640655, 0.61031735, 0.5352278 ,\n",
       "         0.52068377, 0.4808567 , 0.49103174, 0.51490647, 0.45772386,\n",
       "         0.64259034, 0.46386743, 0.4966332 , 0.5419006 , 0.49559748,\n",
       "         0.5324073 , 0.547365  , 0.48449335, 0.48146152, 0.5835738 ,\n",
       "         0.38671663, 0.54231864, 0.47705534, 0.46057332, 0.4765876 ,\n",
       "         0.4687359 , 0.5299549 , 0.48264876, 0.52333677, 0.6613882 ,\n",
       "         0.44603407, 0.5675332 , 0.45756724, 0.5051706 , 0.43008763,\n",
       "         0.495988  , 0.5524024 , 0.48935676, 0.50612825, 0.5380399 ,\n",
       "         0.4890851 , 0.48276645, 0.44985205, 0.49745938, 0.4625007 ,\n",
       "         0.41410372, 0.47519985, 0.5141818 , 0.5802213 , 0.56862354,\n",
       "         0.59389865, 0.4654033 , 0.4866211 , 0.4376723 , 0.53675693,\n",
       "         0.5838027 , 0.5005901 , 0.4387242 , 0.34052864, 0.55623686,\n",
       "         0.47172517, 0.55874807, 0.4658818 , 0.5340581 , 0.4323777 ,\n",
       "         0.52933717, 0.4591887 , 0.5663245 , 0.5025555 , 0.46729133,\n",
       "         0.46725294, 0.46883607, 0.43242836, 0.57648385, 0.5827214 ,\n",
       "         0.54696876, 0.48185682, 0.43388143, 0.4196443 , 0.619354  ,\n",
       "         0.5123604 , 0.4569343 , 0.5101087 , 0.63454145, 0.50939673,\n",
       "         0.58297867, 0.48191214, 0.649867  , 0.5235729 , 0.60826135,\n",
       "         0.5190214 , 0.51337886, 0.5214059 , 0.40982103, 0.47870073,\n",
       "         0.4628214 , 0.55398273, 0.4496093 , 0.5684734 , 0.4472622 ,\n",
       "         0.34931055, 0.49821565, 0.5031247 , 0.53155893, 0.46043608,\n",
       "         0.49211508, 0.40769047, 0.49294162, 0.4572225 , 0.44580382,\n",
       "         0.57241535, 0.5772287 , 0.57767844, 0.39297736, 0.52060443,\n",
       "         0.46675622, 0.453725  , 0.50833505, 0.41159186, 0.5458039 ,\n",
       "         0.62160087, 0.52145267, 0.3358214 , 0.43914512, 0.4567669 ,\n",
       "         0.5540962 , 0.5014848 , 0.40701312, 0.51698655, 0.42367375,\n",
       "         0.5796417 , 0.44149548, 0.46022034, 0.5475982 , 0.48757192,\n",
       "         0.48377934, 0.40706986, 0.4456415 , 0.53734356, 0.5248918 ,\n",
       "         0.43713966, 0.62005466, 0.553583  , 0.40536928, 0.5837627 ,\n",
       "         0.50067216, 0.62676996, 0.5129893 , 0.47617376, 0.53436923,\n",
       "         0.44536904, 0.51668125, 0.5540305 , 0.5168143 , 0.5343007 ,\n",
       "         0.55251664, 0.5059075 , 0.48332   , 0.4636921 , 0.5346317 ,\n",
       "         0.60570306, 0.43856514, 0.51942855, 0.4720008 , 0.60657424,\n",
       "         0.5280086 , 0.5227982 , 0.5231095 , 0.528403  , 0.46927345,\n",
       "         0.49581262, 0.56621724, 0.5154653 , 0.52379924, 0.46903133,\n",
       "         0.553354  , 0.57185686, 0.5534384 , 0.5191285 , 0.5627809 ,\n",
       "         0.47062656, 0.57380086, 0.5063973 , 0.44583774, 0.535154  ,\n",
       "         0.4379747 , 0.5669688 , 0.46039823, 0.45309412, 0.5035037 ,\n",
       "         0.58647215, 0.45156056, 0.424948  , 0.49223158, 0.48381907,\n",
       "         0.529802  , 0.49314398, 0.4793951 , 0.49561962, 0.49647462,\n",
       "         0.5298759 , 0.46220896, 0.59238565, 0.58968693, 0.6017428 ,\n",
       "         0.5265557 , 0.48573586, 0.5982282 , 0.59966904, 0.5258962 ,\n",
       "         0.48833424, 0.49000916, 0.48714852, 0.5356668 , 0.41893855,\n",
       "         0.40844175, 0.58501035, 0.56449324, 0.5338009 , 0.5420297 ,\n",
       "         0.5073178 , 0.45203182, 0.48135144, 0.4820005 , 0.5433399 ,\n",
       "         0.55365384, 0.40205985, 0.5427197 , 0.5018003 , 0.56934196,\n",
       "         0.5997793 , 0.4824757 , 0.5046004 , 0.48591572, 0.49134985,\n",
       "         0.49431634, 0.5053369 , 0.5095073 , 0.5075075 , 0.40121108,\n",
       "         0.5077983 , 0.52792984, 0.555071  , 0.5059171 , 0.5320958 ,\n",
       "         0.50310403, 0.44925058, 0.5734811 , 0.43091568, 0.49927613,\n",
       "         0.50096476, 0.48346627, 0.40707397, 0.59129936, 0.46525973,\n",
       "         0.42511672, 0.6383485 , 0.4489793 , 0.6114826 , 0.58529913,\n",
       "         0.4716801 , 0.58592236, 0.40297577, 0.5321786 , 0.5164089 ,\n",
       "         0.5705215 , 0.42614543, 0.5178189 , 0.49767697, 0.42626366,\n",
       "         0.400357  , 0.46428666, 0.51387376, 0.4913023 , 0.40175286,\n",
       "         0.44235528, 0.5507951 , 0.5224197 , 0.48068252, 0.5643721 ,\n",
       "         0.47416472, 0.5744054 , 0.41211674, 0.5159561 , 0.4269051 ,\n",
       "         0.33723664, 0.48303103, 0.44524843, 0.5506025 , 0.51337117,\n",
       "         0.47436914, 0.4999956 , 0.56055087, 0.5204488 , 0.39256608,\n",
       "         0.5428425 , 0.55342835, 0.5463903 , 0.4547453 , 0.6469696 ,\n",
       "         0.5321157 , 0.4425717 , 0.4972735 , 0.5009342 , 0.45894933,\n",
       "         0.5464717 , 0.56532156, 0.5468966 , 0.49612352, 0.58687115,\n",
       "         0.53652245, 0.46478847, 0.46204838, 0.5502191 , 0.4616048 ,\n",
       "         0.43002465, 0.46692905, 0.54252946, 0.5281797 , 0.48919427,\n",
       "         0.532745  , 0.45255342, 0.42416045, 0.5474619 , 0.5248538 ,\n",
       "         0.51587963, 0.36564228, 0.41390616, 0.5362583 , 0.4480377 ,\n",
       "         0.50699174, 0.56623507, 0.39608386, 0.5198998 , 0.61333495,\n",
       "         0.5545973 , 0.53066534, 0.4630832 , 0.53478366, 0.5732943 ,\n",
       "         0.48682827, 0.47309935, 0.44957897, 0.45223406, 0.49281555,\n",
       "         0.50047934, 0.5737091 , 0.46562496, 0.62386465, 0.47484875,\n",
       "         0.54249465, 0.4390324 , 0.3643042 , 0.41292077]], dtype=float32),\n",
       " Array([[ 0.0339888 ,  0.25236106, -0.0851688 ,  0.11212602, -0.60702693,\n",
       "          0.00289916, -0.09746519, -0.14254496, -0.06265313,  0.2791397 ]],      dtype=float32),\n",
       " Array([[ 0.20330687,  0.28385863,  0.07594076, -0.03722425,  0.2633126 ,\n",
       "         -0.00755761, -0.38492024, -0.14915112, -0.10575105, -0.05497728]],      dtype=float32))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.apply(state.params, x, rngs={'dropout': rng})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b280bbb-b4d2-416e-9abb-cf8c23d89a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10248458  0.2624932   0.33315787 -0.03567007  0.9329739 ]]\n",
      "[[ 0.10248458  0.2624932   0.33315787 -0.03567007  0.9329739 ]]\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    hidden_dim: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.dense = nn.Dense(features=self.hidden_dim)\n",
    "        # Define a parameter named 'bias' with a custom initialization function\n",
    "        self.bias = self.param('bias', nn.initializers.zeros, (self.hidden_dim,))\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # Apply the dense layer and add the bias parameter\n",
    "        return self.compute_with_bias(x)\n",
    "    \n",
    "    def compute_with_bias(self, x):\n",
    "        # Access the bias parameter defined in setup\n",
    "        x = self.dense(x)\n",
    "        return x + self.bias\n",
    "\n",
    "# Example usage\n",
    "rng = jax.random.PRNGKey(0)\n",
    "dummy_input = jnp.ones((1, 10))  # Example input\n",
    "\n",
    "# Initialize the module\n",
    "module = MyModule(hidden_dim=5)\n",
    "params = module.init(rng, dummy_input)\n",
    "\n",
    "# Apply the module using the __call__ method\n",
    "output = module.apply(params, dummy_input)\n",
    "print(output)\n",
    "\n",
    "# Directly call compute_with_bias using the apply method\n",
    "output_direct = module.apply(params, dummy_input, method=MyModule.compute_with_bias)\n",
    "print(output_direct)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jax_tpu_py39)",
   "language": "python",
   "name": "jax_tpu_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
